{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from transformers import MllamaForCausalLM, AutoTokenizer\n",
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "import warnings\n",
    "import gc\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Set up LLM\n",
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "model = MllamaForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(f\"You are running the model on: {model.device}\")\n",
    "\n",
    "## Set up vector database\n",
    "client = chromadb.PersistentClient('../chroma_prod')\n",
    "collection = client.get_or_create_collection('clinical_trials_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_stream(prompt, max_new_tokens=1024):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    try:\n",
    "        streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "        \n",
    "        generation_kwargs = dict(\n",
    "            inputs,\n",
    "            streamer=streamer,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.7,\n",
    "            temperature=0.2,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generation_kwargs['eos_token_id'] = tokenizer.encode(\"</explanation>\")[-1]\n",
    "\n",
    "        # Start the generation in a separate thread\n",
    "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "        thread.start()\n",
    "\n",
    "        generated_text = \"\"\n",
    "        for new_text in streamer:\n",
    "            generated_text += new_text\n",
    "\n",
    "        thread.join()  # Wait for the generation to finish\n",
    "        \n",
    "        # Clear CUDA cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during text generation: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Ensure we always clear the inputs tensor\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(text):\n",
    "    # Extract content within response tags\n",
    "    response_match = re.search(r'<response>(.*?)</response>', text, re.DOTALL)\n",
    "    response = response_match.group(1).strip() if response_match else \"\"\n",
    "    \n",
    "    # Extract content within explanation tags\n",
    "    explanation_match = re.search(r'<explanation>(.*?)</explanation>', text, re.DOTALL)\n",
    "    explanation = explanation_match.group(1).strip() if explanation_match else \"\"\n",
    "    \n",
    "    # Remove any remaining XML-like tags\n",
    "    response = re.sub(r'<.*?>', '', response)\n",
    "    explanation = re.sub(r'<.*?>', '', explanation)\n",
    "    \n",
    "    # Remove any repeated content\n",
    "    response_lines = response.split('\\n')\n",
    "    explanation_lines = explanation.split('\\n')\n",
    "    response = '\\n'.join(dict.fromkeys(response_lines))\n",
    "    explanation = '\\n'.join(dict.fromkeys(explanation_lines))\n",
    "    \n",
    "    return response, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_query(query):\n",
    "    prompt = f\"\"\"You are tasked with thoughtfully expanding a user's query to improve recall from a clinical trials database. The goal is to broaden the search terms while maintaining high relevance and preserving the specificity of key medical conditions.\n",
    "\n",
    "    Original Query:\n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    Instructions:\n",
    "    1. Preserve specific medical conditions mentioned in the query.\n",
    "    2. Include alternative spellings or common abbreviations of medical terms if applicable.\n",
    "    3. If specific medications are mentioned, include their generic names, but keep the specific medication name in the query.\n",
    "    4. Do not add related symptoms or comorbidities unless they are direct synonyms of the condition mentioned.\n",
    "    5. Retain any specific criteria that are central to the query's intent.\n",
    "    6. Expand only to closely related terms or alternative spellings, without generalizing beyond the specific condition mentioned.\n",
    "\n",
    "    Provide the expanded query and a brief explanation of your changes using the following format:\n",
    "\n",
    "    <response>\n",
    "    [Your expanded query here]\n",
    "    </response>\n",
    "\n",
    "    <explanation>\n",
    "    [Brief explanation of changes made]\n",
    "    </explanation>\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Generate expanded query\n",
    "        response = generate_text_stream(prompt)\n",
    "        \n",
    "        if response:\n",
    "            expanded_query, explanation = extract_content(response)\n",
    "            \n",
    "            # Print the expanded query and explanation\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"Original Query:\")\n",
    "            print(query)\n",
    "            print(\"\\nExpanded Query:\")\n",
    "            print(expanded_query)\n",
    "            print(\"\\nExplanation:\")\n",
    "            print(explanation)\n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "            \n",
    "            return expanded_query, explanation\n",
    "        else:\n",
    "            print(\"Failed to generate expanded query.\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during query generalization: {str(e)}\")\n",
    "        return None, None\n",
    "    finally:\n",
    "        # Clear any remaining GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_natural_break(data, min_results=10, threshold_multiplier=3.0):\n",
    "    if len(data) <= min_results:\n",
    "        return len(data)\n",
    "    \n",
    "    # Calculate differences between consecutive elements\n",
    "    differences = np.diff(data)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the differences\n",
    "    mean_diff = np.mean(differences[min_results-1:])  # Consider only differences after min_results\n",
    "    std_diff = np.std(differences[min_results-1:])\n",
    "    \n",
    "    # Set the threshold for a \"significant\" difference\n",
    "    threshold = mean_diff + threshold_multiplier * std_diff\n",
    "    print(threshold)\n",
    "    \n",
    "    # Find the first index after min_results where the difference exceeds the threshold\n",
    "    break_indices = np.where(differences[min_results-1:] > threshold)[0]\n",
    "    \n",
    "    if len(break_indices) > 0:\n",
    "        return min_results + break_indices[0]\n",
    "    else:\n",
    "        return len(data)\n",
    "\n",
    "def tag_relevant_documents(documents, min_results=10):\n",
    "    \n",
    "    distances = np.array(documents['distances'][0])\n",
    "    \n",
    "    # Find the natural break\n",
    "    cutoff_index = find_natural_break(distances, min_results)\n",
    "    \n",
    "    # Add relevance indicator to each result\n",
    "    relevance = ['relevant' if i < cutoff_index else 'less_relevant' for i in range(len(distances))]\n",
    "    \n",
    "    # Add the relevance indicator to the results\n",
    "    return {\n",
    "        'ids': documents['ids'][0],\n",
    "        'distances': documents['distances'][0],\n",
    "        'metadatas': documents['metadatas'][0],\n",
    "        'documents': documents['documents'][0],\n",
    "        'relevance': relevance\n",
    "    }\n",
    "    \n",
    "def filter_relevant_documents(documents):\n",
    "        relevant_results = {\n",
    "        'documents': [],\n",
    "        'metadatas': [],\n",
    "        'distances': [],\n",
    "        'ids': []\n",
    "    }\n",
    "    \n",
    "        for i, relevance in enumerate(documents['relevance']):\n",
    "            if relevance == 'relevant':\n",
    "                relevant_results['documents'].append(documents['documents'][i])\n",
    "                relevant_results['metadatas'].append(documents['metadatas'][i])\n",
    "                relevant_results['distances'].append(documents['distances'][i])\n",
    "                relevant_results['ids'].append(documents['ids'][i])\n",
    "        \n",
    "        return relevant_results\n",
    "\n",
    "def plot_search_distances(documents):\n",
    "    # Extract distances and relevance\n",
    "    distances = documents['distances']\n",
    "    relevance = documents['relevance']\n",
    "    titles = [meta.get('title', f\"Document {i}\") for i, meta in enumerate(documents['metadatas'])]\n",
    "    \n",
    "    # Create indices for x-axis\n",
    "    indices = list(range(len(distances)))\n",
    "    \n",
    "    # Calculate differences\n",
    "    differences = np.diff(distances)\n",
    "    diff_indices = indices[1:]  # Differences have one less point\n",
    "    \n",
    "    # Separate relevant and less relevant results\n",
    "    relevant_indices = [i for i, rel in enumerate(relevance) if rel == 'relevant']\n",
    "    relevant_distances = [distances[i] for i in relevant_indices]\n",
    "    relevant_titles = [titles[i] for i in relevant_indices]\n",
    "    \n",
    "    less_relevant_indices = [i for i, rel in enumerate(relevance) if rel == 'less_relevant']\n",
    "    less_relevant_distances = [distances[i] for i in less_relevant_indices]\n",
    "    less_relevant_titles = [titles[i] for i in less_relevant_indices]\n",
    "    \n",
    "    # Create the plot with two subplots\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1,\n",
    "                        subplot_titles=(\"Search Result Distances\", \"Differences in Distances\"))\n",
    "    \n",
    "    # Plot relevant results (distances)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=relevant_indices, \n",
    "            y=relevant_distances, \n",
    "            mode='markers',\n",
    "            name='Relevant',\n",
    "            marker=dict(color='blue', size=10),\n",
    "            text=relevant_titles,\n",
    "            hovertemplate=\"<b>%{text}</b><br>Index: %{x}<br>Distance: %{y:.4f}<extra></extra>\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Plot less relevant results (distances)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=less_relevant_indices, \n",
    "            y=less_relevant_distances, \n",
    "            mode='markers',\n",
    "            name='Less Relevant',\n",
    "            marker=dict(color='red', size=10),\n",
    "            text=less_relevant_titles,\n",
    "            hovertemplate=\"<b>%{text}</b><br>Index: %{x}<br>Distance: %{y:.4f}<extra></extra>\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Plot differences with consistent color scheme\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=diff_indices[:len(relevant_indices)-1],\n",
    "            y=differences[:len(relevant_indices)-1],\n",
    "            mode='lines+markers',\n",
    "            name='Relevant Differences',\n",
    "            line=dict(color='blue'),\n",
    "            marker=dict(size=6),\n",
    "            hovertemplate=\"Index: %{x}<br>Difference: %{y:.4f}<extra></extra>\"\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=diff_indices[len(relevant_indices)-1:],\n",
    "            y=differences[len(relevant_indices)-1:],\n",
    "            mode='lines+markers',\n",
    "            name='Less Relevant Differences',\n",
    "            line=dict(color='red'),\n",
    "            marker=dict(size=6),\n",
    "            hovertemplate=\"Index: %{x}<br>Difference: %{y:.4f}<extra></extra>\"\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add vertical lines at the break point\n",
    "    break_point = len(relevant_indices)\n",
    "    fig.add_vline(x=break_point - 0.5, line_dash=\"dash\", line_color=\"green\", \n",
    "                  annotation_text=\"Relevance Break\", row=1, col=1)\n",
    "    fig.add_vline(x=break_point - 0.5, line_dash=\"dash\", line_color=\"green\", row=2, col=1)\n",
    "    \n",
    "    # Customize the plot\n",
    "    fig.update_layout(\n",
    "        height=800,  # Increase height to accommodate two subplots\n",
    "        title_text=\"Search Result Distances and Differences\",\n",
    "        legend_title=\"Relevance\",\n",
    "        hovermode='closest'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Result Index\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Distance\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Difference\", row=2, col=1)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_trials(trials, query):\n",
    "    doc_summary_collection = []\n",
    "    if trials and trials['documents']:\n",
    "        for i, doc in enumerate(trials['documents']):\n",
    "            title = trials['metadatas'][i]['title']\n",
    "\n",
    "            prompt = f\"\"\"Summarize the following document in the context of the original query. Focus only on information directly relevant to the query.\n",
    "\n",
    "            Original Query:\n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "\n",
    "            Document Title: {title}\n",
    "\n",
    "            Document Content:\n",
    "            {doc}\n",
    "\n",
    "            Instructions:\n",
    "            1. Provide a brief summary (2-3 sentences) highlighting key points relevant to the query.\n",
    "            2. Mention any specific therapies or treatments discussed in the document that relate to the query.\n",
    "            3. Include only the most pertinent numerical data, if any.\n",
    "            4. Use clear, concise language. Avoid repetition.\n",
    "\n",
    "            Provide the summary and an explanation of the document's relevance using the following format:\n",
    "\n",
    "            <response>\n",
    "            [Insert your 2-3 sentence summary here]\n",
    "            </response>\n",
    "\n",
    "            <explanation>\n",
    "            [Explain how this document is relevant to the original query. If not relevant, briefly state why.]\n",
    "            </explanation>\n",
    "            \"\"\"\n",
    "\n",
    "            # Generate summary\n",
    "            response = generate_text_stream(prompt)\n",
    "            \n",
    "            if response:\n",
    "                summary, explanation = extract_content(response)\n",
    "                doc_summary_collection.append({'title': title, 'summary': summary, 'explanation': explanation})\n",
    "                \n",
    "                # Print the summary immediately after generation\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(f\"{i}. Title: {title}\")\n",
    "                print(\"=\"*50)\n",
    "                print(\"\\nSummary:\")\n",
    "                print(summary)\n",
    "                print(\"\\nExplanation:\")\n",
    "                print(explanation)\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "            else:\n",
    "                print(f\"Failed to generate summary for document: {title}\")\n",
    "            \n",
    "            # Clear any remaining GPU memory\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    return doc_summary_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overall_summary(trials_summary_collection, query):\n",
    "    # Combine all summaries into a single string\n",
    "    all_summaries = \"\\n\\n\".join([f\"Title: {trial['title']}\\nSummary: {trial['summary']}\" for trial in trials_summary_collection])\n",
    "\n",
    "    prompt = f\"\"\"Summarize the following document in the context of the original query. Focus only on information directly relevant to the query.\n",
    "\n",
    "        Original Query:\n",
    "        <query>\n",
    "        {query}\n",
    "        </query>\n",
    "\n",
    "        Document Content:\n",
    "        {all_summaries}\n",
    "\n",
    "        Instructions:\n",
    "        1. Analyze the document summaries and extract key information relevant to the original query.\n",
    "        2. Synthesize this information into a coherent, detailed answer addressing the user's question.\n",
    "        3. Include specific therapies, treatments, or clinical trial details mentioned in the summaries that are directly relevant to the query.\n",
    "        4. Present any pertinent numerical data or statistics from the summaries.\n",
    "        5. Ensure the answer is comprehensive yet focused, avoiding irrelevant information.\n",
    "        6. Use clear, professional language appropriate for discussing medical topics.\n",
    "        7. If there are conflicting findings or information gaps, mention these briefly.\n",
    "\n",
    "        Provide your response using the following format:\n",
    "\n",
    "        <response>\n",
    "        [Insert your comprehensive summary here. This should be a detailed few paragraphs covering the main points, relevant information, and data that directly address the query.]\n",
    "        </response>\n",
    "\n",
    "        <explanation>\n",
    "        [Explain how you synthesized this information from the document. Discuss any challenges in interpreting the data, conflicting information, or gaps in the available information. Explain how you determined which information was most relevant to include in the summary based on the original query.]\n",
    "        </explanation>\"\"\"\n",
    "\n",
    "    # Generate overall summary\n",
    "    response = generate_text_stream(prompt, max_new_tokens=4096)\n",
    "    \n",
    "    if response:\n",
    "        overall_summary, explanation = extract_content(response)\n",
    "        \n",
    "        # Print the overall summary immediately after generation\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Overall Summary\")\n",
    "        print(\"=\"*50)\n",
    "        if overall_summary:\n",
    "            print(\"\\nSummary:\")\n",
    "            print(overall_summary)\n",
    "        else:\n",
    "            print(\"\\nWarning: No summary was generated.\")\n",
    "        \n",
    "        if explanation:\n",
    "            print(\"\\nExplanation:\")\n",
    "            print(explanation)\n",
    "        else:\n",
    "            print(\"\\nWarning: No explanation was provided.\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "    else:\n",
    "        print(\"Failed to generate overall summary\")\n",
    "        overall_summary = \"\"\n",
    "        explanation = \"\"\n",
    "    \n",
    "    # Clear any remaining GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return response, overall_summary, explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalize the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the latest therapies for perimenopause?\"\n",
    "# query = \"What are the latest therapies for lpa?\"\n",
    "expanded_query, explanation = generalize_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve documents with relevant distance measure and summarize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_results = 5\n",
    "max_results = 100\n",
    "trials = collection.query(query_texts=expanded_query, n_results=max_results, include=[\"documents\", \"metadatas\", \"distances\"])\n",
    "trials = tag_relevant_documents(trials, min_results=min_results)\n",
    "plot_search_distances(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_trials = filter_relevant_documents(trials)\n",
    "trial_summary_collection = summarize_trials(relevant_trials, expanded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, summary, explanation = generate_overall_summary(trial_summary_collection, expanded_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
